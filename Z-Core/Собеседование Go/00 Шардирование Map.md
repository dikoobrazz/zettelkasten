2025022422:19
___
Date: 24-02-2025 | 22:19
Tags: #
mapofcontents: [[zero-links|OO Links]]
___
## Шардирование (sharding) Map

> Шардирование заключается в том, чтобы разделить одну большую map на несколько меньших "шардов" (сегментов), каждый из которых защищен своим собственным мьютексом. Это уменьшает конкуренцию за блокировку, так как разные горутины могут работать с разными шардами одновременно.

**пример кода с подробным объяснением:**
```go
package main

import (
	"fmt"
	"sync"
	"hash/fnv" // Для создания хэша ключа
)

// ShardedMap представляет структуру с шардированной map
type ShardedMap struct {
	shards []*shard // Срез шардов
	numShards int    // Количество шардов
}

// shard — один сегмент map с мьютексом
type shard struct {
	mu   sync.RWMutex
	data map[string]int
}

// NewShardedMap создает новую шардированную map с заданным количеством шардов
func NewShardedMap(numShards int) *ShardedMap {
	shards := make([]*shard, numShards)
	for i := 0; i < numShards; i++ {
		shards[i] = &shard{
			data: make(map[string]int),
		}
	}
	return &ShardedMap{
		shards:    shards,
		numShards: numShards,
	}
}

// getShardIndex вычисляет индекс шарда на основе хэша ключа
func (sm *ShardedMap) getShardIndex(key string) int {
	h := fnv.New32a()
	h.Write([]byte(key))
	return int(h.Sum32()) % sm.numShards
}

// Set записывает значение в соответствующий шард
func (sm *ShardedMap) Set(key string, value int) {
	shardIdx := sm.getShardIndex(key)
	shard := sm.shards[shardIdx]
	shard.mu.Lock()
	defer shard.mu.Unlock()
	shard.data[key] = value
}

// Get получает значение из соответствующего шарда
func (sm *ShardedMap) Get(key string) (int, bool) {
	shardIdx := sm.getShardIndex(key)
	shard := sm.shards[shardIdx]
	shard.mu.RLock()
	defer shard.mu.RUnlock()
	value, ok := shard.data[key]
	return value, ok
}

func main() {
	// Создаем шардированную map с 4 шардами
	sm := NewShardedMap(4)
	var wg sync.WaitGroup

	// Запускаем 10 горутин для записи
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func(i int) {
			defer wg.Done()
			key := fmt.Sprintf("key%d", i)
			sm.Set(key, i)
		}(i)
	}

	wg.Wait()

	// Проверяем значения
	for i := 0; i < 10; i++ {
		key := fmt.Sprintf("key%d", i)
		if val, ok := sm.Get(key); ok {
			fmt.Printf("Key: %s, Value: %d\n", key, val)
		}
	}
}
```

### Объяснение кода:

#### 1. Структура данных:

- **ShardedMap**: Основная структура, которая содержит срез шардов (shards) и их количество (numShards). Каждый шард — это отдельная map с собственным мьютексом.
- **shard**: Структура одного шарда, включающая sync.RWMutex для синхронизации и map[string]int для хранения данных.

#### 2. Инициализация:

- **NewShardedMap(numShards int)**: Создает экземпляр ShardedMap с заданным количеством шардов. Каждый шард инициализируется с пустой map.
  
#### 3. Разделение ключей:

- **getShardIndex(key string)**: Функция вычисляет, в какой шард попадет ключ. Мы используем хэш-функцию fnv для получения числового значения из строки ключа, а затем берем остаток от деления на количество шардов (% numShards). Это обеспечивает равномерное распределение ключей по шардам.
  
#### 4. Операции записи и чтения:

- **Set(key string, value int)**:  
    1. Определяет индекс шарда для заданного ключа.
    2. Блокирует мьютекс этого шарда с помощью Lock() (для записи).
    3. Записывает значение в map шарда.
    4. Разблокирует мьютекс через defer.

- **Get(key string)**:  
    1. Определяет индекс шарда.
    2. Использует RLock() (для чтения), чтобы позволить параллельное чтение из того же шарда.
    3. Возвращает значение и флаг существования ключа.
    4. Разблокирует через defer.

#### 5. Пример в main:

- Создается ShardedMap с 4 шардами.
- 10 горутин параллельно записывают значения в map.
- После завершения записи проверяем, что все данные доступны через Get.
### Преимущества:
  
- **Снижение конкуренции**: Вместо одной блокировки на всю map у нас есть отдельные мьютексы для каждого шарда. Если ключи распределяются равномерно, горутины реже блокируют друг друга.
- **Масштабируемость**: Чем больше шардов, тем лучше распараллеливание (до определенного предела).
### Нюансы:

- **Распределение ключей**: Если хэш-функция плохо распределяет ключи, один шард может стать "горячей точкой".
- **Оверхед**: При небольшом количестве данных или операций дополнительные мьютексы и структуры могут быть избыточными по сравнению с простой sync.Mutex.
- **Число шардов**: Обычно выбирают степень двойки (например, 4, 8, 16), чтобы оптимизировать деление. Слишком много шардов увеличивает накладные расходы, слишком мало — конкуренцию.
  
Этот подход идеален для высоконагруженных систем, где много параллельных операций с map

-----
**Zero-Links**  (Внутренние ссылки) Линки - ключевые слова
-

------
**Links** (Внешние ссылки)
-
