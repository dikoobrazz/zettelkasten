2025030715:34
___
Date: 07-03-2025 | 15:34
Tags: #
mapofcontents: [[zero-links|OO Links]]
___
## Как в кафку загнать 100к сообщений в секунду?

> Загрузка **100 тысяч сообщений в секунду** в Apache Kafka — это высоконагруженный сценарий, который требует оптимизации producer'а, брокера и инфраструктуры. Kafka спроектирован для таких объемов, но нужно правильно настроить систему.

---
### Почему это возможно?

Kafka обеспечивает высокую пропускную способность благодаря:

- **Партиционированию**: Топики делятся на партиции, которые распределяются по брокерам.
- **Асинхронной записи**: Producer может отправлять сообщения без ожидания немедленного подтверждения.
- **Батчингу**: Сообщения группируются перед отправкой для снижения накладных расходов.

Для 100к сообщений/с нужно оптимизировать все уровни: код producer'а, конфигурацию Kafka и серверное окружение.

---
### Шаги для достижения 100к сообщений/с

#### 1. Оптимизация Producer'а в Go

Используем библиотеку github.com/segmentio/kafka-go, которая хорошо подходит для высокопроизводительных сценариев.

**Пример кода**:
```go
package main

import (
    "context"
    "fmt"
    "github.com/segmentio/kafka-go"
    "time"
)

func main() {
    // Создаем writer с оптимизированными настройками
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers:      []string{"localhost:9092"}, // Список брокеров
        Topic:        "high-throughput-topic",
        BatchSize:    1000,        // Кол-во сообщений в батче
        BatchBytes:   10 << 20,    // 10MB максимальный размер батча
        BatchTimeout: 5 * time.Millisecond, // Максимальное ожидание батча
        Async:        true,        // Асинхронная отправка
        Balancer:     &kafka.RoundRobin{}, // Распределение по партициям
    })
    defer writer.Close()

    // Генерация сообщений
    messages := make([]kafka.Message, 0, 1000)
    start := time.Now()
    for i := 0; ; i++ {
        msg := kafka.Message{
            Key:   []byte(fmt.Sprintf("key-%d", i)),
            Value: []byte(fmt.Sprintf("message-%d", i)),
        }
        messages = append(messages, msg)

        // Отправка батча
        if len(messages) >= 1000 {
            err := writer.WriteMessages(context.Background(), messages...)
            if err != nil {
                fmt.Printf("Error: %v\n", err)
            }
            messages = messages[:0] // Очистка слайса
        }

        // Проверка скорости
        if i%100000 == 0 && i > 0 {
            elapsed := time.Since(start).Seconds()
            rate := float64(i) / elapsed
            fmt.Printf("Sent %d messages, rate: %.2f msg/s\n", i, rate)
            start = time.Now()
        }
    }
}
```

- **Ключевые настройки**:
    - `BatchSize`: 1000 сообщений в батче для уменьшения числа вызовов.
    - `BatchBytes`: 10MB для больших батчей.
    - `BatchTimeout`: 5мс, чтобы не задерживать отправку.
    - `Async: true`: Не ждем подтверждения (увеличивает скорость, но снижает гарантию доставки).

**Совет**: Для гарантии доставки (`at least once`) уберите `Async` и добавьте `RequiredAcks: -1`.

---
#### 2. Настройка Kafka Broker

Kafka должна быть оптимизирована для высокой пропускной способности:

- **Количество партиций**: Для 100к сообщений/с нужно достаточно партиций (например, 10-50).
```bash
kafka-topics.sh --create --topic high-throughput-topic --partitions 50 --replication-factor 2 --bootstrap-server localhost:9092
```

- 50 партиций позволяют распараллелить запись между брокерами.

- **Конфигурация брокера** (`server.properties`):
```properties
num.io.threads=16          # Больше потоков для записи
num.network.threads=8      # Больше потоков для сети
log.flush.interval.ms=1000 # Реже сбрасывать на диск
socket.send.buffer.bytes=1048576 # Увеличить буфер отправки (1MB)
```

- **Репликация**: Установите `replication.factor=2` для отказоустойчивости, но не больше, чтобы не снижать производительность.

**Совет**: Используйте кластер из 3+ брокеров для распределения нагрузки.

---
#### 3. Инфраструктура

- **Серверы**:
    - Минимум 8 CPU, 16GB RAM на брокер.
    - SSD-диски для быстрой записи (Kafka сильно зависит от I/O).
- **Сеть**:
    - Gigabit Ethernet (1Gbps) или выше.
    - Низкая задержка между producer'ом и брокерами.
- **Развертывание**:
    - Используйте Docker или Kubernetes для кластера Kafka:
```yml
apiVersion: v1
kind: Pod
metadata:
  name: kafka-broker
spec:
  containers:
  - name: kafka
    image: bitnami/kafka:latest
    env:
    - name: KAFKA_CFG_NUM_PARTITIONS
      value: "50"
```

---
#### 4. Параллелизм в Producer'е

Для 100к/с одного writer'а может не хватить. Используйте несколько горутин:

```go
func produceMessages(writer *kafka.Writer, startID int, count int) {
    messages := make([]kafka.Message, 0, 1000)
    for i := startID; i < startID+count; i++ {
        messages = append(messages, kafka.Message{
            Key:   []byte(fmt.Sprintf("key-%d", i)),
            Value: []byte(fmt.Sprintf("message-%d", i)),
        })
        if len(messages) >= 1000 {
            writer.WriteMessages(context.Background(), messages...)
            messages = messages[:0]
        }
    }
    if len(messages) > 0 {
        writer.WriteMessages(context.Background(), messages...)
    }
}

func main() {
    writer := kafka.NewWriter(kafka.WriterConfig{
        Brokers:      []string{"localhost:9092"},
        Topic:        "high-throughput-topic",
        BatchSize:    1000,
        BatchBytes:   10 << 20,
        BatchTimeout: 5 * time.Millisecond,
        Async:        true,
    })
    defer writer.Close()

    numGoroutines := 10
    messagesPerGoroutine := 1000000 / numGoroutines
    var wg sync.WaitGroup
    start := time.Now()

    for i := 0; i < numGoroutines; i++ {
        wg.Add(1)
        go func(id int) {
            defer wg.Done()
            produceMessages(writer, id*messagesPerGoroutine, messagesPerGoroutine)
        }(i)
    }
    wg.Wait()

    elapsed := time.Since(start).Seconds()
    fmt.Printf("Sent %d messages in %.2fs, rate: %.2f msg/s\n", 1000000, elapsed, 1000000/elapsed)
}
```

- **Логика**: 10 горутин отправляют по 100к сообщений, распределяя нагрузку.

---
#### 5. Тестирование и мониторинг

- **Тестирование**:
    - Используйте `kafka-producer-perf-test` для проверки:
```bash
kafka-producer-perf-test.sh --topic high-throughput-topic --num-records 1000000 --throughput 100000 --record-size 100 --producer-props bootstrap.servers=localhost:9092
```

- **Мониторинг**:
    - Подключите Prometheus + Grafana для метрик Kafka (лаг consumer'а, пропускная способность).

---
### Ключевые моменты для 100к/с

1. **Батчинг**: Увеличьте `BatchSize` и `BatchBytes`, уменьшите `BatchTimeout`.
2. **Партиции**: 50+ партиций для параллелизма.
3. **Асинхронность**: `Async: true` для скорости (или `RequiredAcks: 1` для баланса).
4. **Горутины**: Используйте несколько producer'ов для распределения нагрузки.
5. **Инфраструктура**: Мощные серверы и быстрая сеть.

---
### Ограничения и решения

- **Сеть**: Если 100к сообщений по 1KB = 100MB/s, нужна сеть 1Gbps+.
- **Диск**: SSD с высокой скоростью записи (500MB/s+).
- **CPU**: Многоядерные процессоры для обработки I/O.

Если цель не достигнута:

- Увеличьте число брокеров (3-5).
- Оптимизируйте размер сообщения (меньше данных = выше скорость).

---
### Итог

Для 100к сообщений/с в Kafka с Go:

- Настройте producer с батчингом и асинхронностью.
- Используйте 10+ горутин для параллельной отправки.
- Создайте топик с 50+ партициями.
- Разверните кластер Kafka на мощных серверах.

С этими настройками Kafka легко справится с нагрузкой.

-----
**Zero-Links**  (Внутренние ссылки) Линки - ключевые слова
-

------
**Links** (Внешние ссылки)
-
